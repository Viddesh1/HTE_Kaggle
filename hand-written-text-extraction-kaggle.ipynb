{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport pandas as pd\nimport string\nimport matplotlib.pyplot as plt\nimport os\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\nfrom keras.models import Model\nfrom keras.activations import relu, sigmoid, softmax\nimport keras.backend as K\nfrom keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-30T07:19:23.697631Z","iopub.execute_input":"2023-09-30T07:19:23.697975Z","iopub.status.idle":"2023-09-30T07:19:23.704815Z","shell.execute_reply.started":"2023-09-30T07:19:23.697949Z","shell.execute_reply":"2023-09-30T07:19:23.703855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/iam-handwriting-word-database/iam_words/words.txt') as f:\n    contents = f.readlines()\n\nlines = [line.strip() for line in contents][18:]\nlines[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:19:25.604409Z","iopub.execute_input":"2023-09-30T07:19:25.605813Z","iopub.status.idle":"2023-09-30T07:19:25.637562Z","shell.execute_reply.started":"2023-09-30T07:19:25.605763Z","shell.execute_reply":"2023-09-30T07:19:25.636106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_label_len = 0\n\nchar_list = \"!\\\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" \n\n# string.ascii_letters + string.digits (Chars & Digits)\n# or \n# \"!\\\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n\nprint(char_list, len(char_list))\n\ndef encode_to_labels(txt):\n    # encoding each output word into digits\n    dig_lst = []\n    for index, chara in enumerate(txt):\n        dig_lst.append(char_list.index(chara))\n        \n    return dig_lst","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:19:27.341330Z","iopub.execute_input":"2023-09-30T07:19:27.341771Z","iopub.status.idle":"2023-09-30T07:19:27.348700Z","shell.execute_reply.started":"2023-09-30T07:19:27.341741Z","shell.execute_reply":"2023-09-30T07:19:27.347570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = []\nlabels = []\n\nRECORDS_COUNT = 10000","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:19:29.235066Z","iopub.execute_input":"2023-09-30T07:19:29.235691Z","iopub.status.idle":"2023-09-30T07:19:29.241140Z","shell.execute_reply.started":"2023-09-30T07:19:29.235649Z","shell.execute_reply":"2023-09-30T07:19:29.239486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = []\ntrain_labels = []\ntrain_input_length = []\ntrain_label_length = []\ntrain_original_text = []\n\nvalid_images = []\nvalid_labels = []\nvalid_input_length = []\nvalid_label_length = []\nvalid_original_text = []\n\ninputs_length = []\nlabels_length = []","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:19:30.459482Z","iopub.execute_input":"2023-09-30T07:19:30.459945Z","iopub.status.idle":"2023-09-30T07:19:30.467340Z","shell.execute_reply.started":"2023-09-30T07:19:30.459907Z","shell.execute_reply":"2023-09-30T07:19:30.466125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_image(img):\n    \"\"\"\n    Converts image to shape (32, 128, 1) & normalize\n    \"\"\"\n    w, h = img.shape\n    \n#     _, img = cv2.threshold(img, \n#                            128, \n#                            255, \n#                            cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n    \n    # Aspect Ratio Calculation\n    new_w = 32\n    new_h = int(h * (new_w / w))\n    img = cv2.resize(img, (new_h, new_w))\n    w, h = img.shape\n    \n    img = img.astype('float32')\n    \n    # Converts each to (32, 128, 1)\n    if w < 32:\n        add_zeros = np.full((32-w, h), 255)\n        img = np.concatenate((img, add_zeros))\n        w, h = img.shape\n    \n    if h < 128:\n        add_zeros = np.full((w, 128-h), 255)\n        img = np.concatenate((img, add_zeros), axis=1)\n        w, h = img.shape\n        \n    if h > 128 or w > 32:\n        dim = (128,32)\n        img = cv2.resize(img, dim)\n    \n    img = cv2.subtract(255, img)\n    \n    img = np.expand_dims(img, axis=2)\n    \n    # Normalize \n    img = img / 255\n    \n    return img","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:19:32.593296Z","iopub.execute_input":"2023-09-30T07:19:32.593754Z","iopub.status.idle":"2023-09-30T07:19:32.602739Z","shell.execute_reply.started":"2023-09-30T07:19:32.593722Z","shell.execute_reply":"2023-09-30T07:19:32.601283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, line in enumerate(lines):\n    splits = line.split(' ')\n    status = splits[1]\n    \n    if status == 'ok':\n        word_id = splits[0]\n        word = \"\".join(splits[8:])\n        \n        splits_id = word_id.split('-')\n        filepath = '/kaggle/input/iam-handwriting-word-database/iam_words/words/{}/{}-{}/{}.png'.format(splits_id[0], \n                                                  splits_id[0], \n                                                  splits_id[1], \n                                                  word_id)\n        \n        # processing on image\n        img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n        try:\n            img = process_image(img)\n        except:\n            continue\n            \n        # processing on label\n        try:\n            label = encode_to_labels(word)\n        except:\n            continue\n        \n        if index % 10 == 0:\n            valid_images.append(img)\n            valid_labels.append(label)\n            valid_input_length.append(31)\n            valid_label_length.append(len(word))\n            valid_original_text.append(word)\n        else:\n            train_images.append(img)\n            train_labels.append(label)\n            train_input_length.append(31)\n            train_label_length.append(len(word))\n            train_original_text.append(word)\n        \n        if len(word) > max_label_len:\n            max_label_len = len(word)\n    \n    if index >= RECORDS_COUNT:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:19:36.556016Z","iopub.execute_input":"2023-09-30T07:19:36.556404Z","iopub.status.idle":"2023-09-30T07:19:52.929826Z","shell.execute_reply.started":"2023-09-30T07:19:36.556377Z","shell.execute_reply":"2023-09-30T07:19:52.928432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_padded_label = pad_sequences(train_labels, \n                             maxlen=max_label_len, \n                             padding='post',\n                             value=len(char_list))\n\nvalid_padded_label = pad_sequences(valid_labels, \n                             maxlen=max_label_len, \n                             padding='post',\n                             value=len(char_list))","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:20:00.816723Z","iopub.execute_input":"2023-09-30T07:20:00.817906Z","iopub.status.idle":"2023-09-30T07:20:00.846080Z","shell.execute_reply.started":"2023-09-30T07:20:00.817858Z","shell.execute_reply":"2023-09-30T07:20:00.844861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_padded_label.shape, valid_padded_label.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:20:03.637402Z","iopub.execute_input":"2023-09-30T07:20:03.637884Z","iopub.status.idle":"2023-09-30T07:20:03.645587Z","shell.execute_reply.started":"2023-09-30T07:20:03.637851Z","shell.execute_reply":"2023-09-30T07:20:03.644345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_images = np.asarray(train_images)\ntrain_input_length = np.asarray(train_input_length)\ntrain_label_length = np.asarray(train_label_length)\n\nvalid_images = np.asarray(valid_images)\nvalid_input_length = np.asarray(valid_input_length)\nvalid_label_length = np.asarray(valid_label_length)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:20:07.004827Z","iopub.execute_input":"2023-09-30T07:20:07.005720Z","iopub.status.idle":"2023-09-30T07:20:07.244156Z","shell.execute_reply.started":"2023-09-30T07:20:07.005478Z","shell.execute_reply":"2023-09-30T07:20:07.242810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:20:14.468773Z","iopub.execute_input":"2023-09-30T07:20:14.469158Z","iopub.status.idle":"2023-09-30T07:20:14.478354Z","shell.execute_reply.started":"2023-09-30T07:20:14.469131Z","shell.execute_reply":"2023-09-30T07:20:14.476796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input with shape of height=32 and width=128 \ninputs = Input(shape=(32,128,1))\n \n# convolution layer with kernel size (3,3)\nconv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n# poolig layer with kernel size (2,2)\npool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n \nconv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\npool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n \nconv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n \nconv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n\n# poolig layer with kernel size (2,1)\npool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n \nconv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n\n# Batch normalization layer\nbatch_norm_5 = BatchNormalization()(conv_5)\n \nconv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\nbatch_norm_6 = BatchNormalization()(conv_6)\npool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n \nconv_7 = Conv2D(512, (2,2), activation = 'relu')(pool_6)\n \nsqueezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n \n# bidirectional LSTM layers with units=128\nblstm_1 = Bidirectional(LSTM(256, return_sequences=True, dropout = 0.2))(squeezed)\nblstm_2 = Bidirectional(LSTM(256, return_sequences=True, dropout = 0.2))(blstm_1)\n \noutputs = Dense(len(char_list)+1, activation = 'softmax')(blstm_2)\n\n# model to be used at test time\nact_model = Model(inputs, outputs)\nact_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:21:24.612197Z","iopub.execute_input":"2023-09-30T07:21:24.612583Z","iopub.status.idle":"2023-09-30T07:21:26.059661Z","shell.execute_reply.started":"2023-09-30T07:21:24.612558Z","shell.execute_reply":"2023-09-30T07:21:26.058420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"the_labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\ninput_length = Input(name='input_length', shape=[1], dtype='int64')\nlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\ndef ctc_lambda_func(args):\n    y_pred, labels, input_length, label_length = args\n    \n    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n\nloss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, the_labels, input_length, label_length])\n\n#model to be used at training time\nmodel = Model(inputs=[inputs, the_labels, input_length, label_length], outputs=loss_out)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:21:42.094220Z","iopub.execute_input":"2023-09-30T07:21:42.094709Z","iopub.status.idle":"2023-09-30T07:21:42.229627Z","shell.execute_reply.started":"2023-09-30T07:21:42.094677Z","shell.execute_reply":"2023-09-30T07:21:42.228178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\nepochs = 30\ne = str(epochs)\noptimizer_name = 'sgd'","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:21:45.159923Z","iopub.execute_input":"2023-09-30T07:21:45.161148Z","iopub.status.idle":"2023-09-30T07:21:45.166342Z","shell.execute_reply.started":"2023-09-30T07:21:45.161093Z","shell.execute_reply":"2023-09-30T07:21:45.165184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the directory path within /kaggle/output/\ncheckpoint_directory = '/kaggle/working/checkpoint_1/' # /kaggle/output/checkpoint_1/\n\n# Create the directory if it doesn't exist\nif not os.path.exists(checkpoint_directory):\n    os.makedirs(checkpoint_directory)  # Use os.makedirs() to create parent directories if needed\n\n# Now you can save your data or model checkpoints to the checkpoint_directory\n# For example, if you want to save a model checkpoint:\n# model.save(os.path.join(checkpoint_directory, 'my_model.h5'))","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:23:05.167705Z","iopub.execute_input":"2023-09-30T07:23:05.168119Z","iopub.status.idle":"2023-09-30T07:23:05.175008Z","shell.execute_reply.started":"2023-09-30T07:23:05.168092Z","shell.execute_reply":"2023-09-30T07:23:05.173680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = optimizer_name, metrics=['accuracy'])\n\nfilepath=\"/kaggle/working/checkpoint_1/{}o-{}r-{}e-{}t-{}v.hdf5\".format(optimizer_name,\n                                          str(RECORDS_COUNT),\n                                          str(epochs),\n                                          str(train_images.shape[0]),\n                                          str(valid_images.shape[0]))\n\ncheckpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\ncallbacks_list = [checkpoint]","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:24:00.819065Z","iopub.execute_input":"2023-09-30T07:24:00.819526Z","iopub.status.idle":"2023-09-30T07:24:00.836005Z","shell.execute_reply.started":"2023-09-30T07:24:00.819478Z","shell.execute_reply":"2023-09-30T07:24:00.834865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x=[train_images, train_padded_label, train_input_length, train_label_length],\n                    y=np.zeros(len(train_images)),\n                    batch_size=batch_size, \n                    epochs=epochs, \n                    validation_data=([valid_images, valid_padded_label, valid_input_length, valid_label_length], [np.zeros(len(valid_images))]),\n                    verbose=2,\n                    callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:24:12.236234Z","iopub.execute_input":"2023-09-30T07:24:12.236601Z","iopub.status.idle":"2023-09-30T07:26:36.955445Z","shell.execute_reply.started":"2023-09-30T07:24:12.236575Z","shell.execute_reply":"2023-09-30T07:26:36.953141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the history object in excel file using pandas. \n# pip install openpyxl \n\nhistory_dict = {\n    'epoch': list(range(1, len(history_object.history['loss']) + 1)),\n    'loss': history_object.history['loss'],\n    'accuracy': history_object.history['accuracy'],\n    'val_loss': history_object.history['val_loss'],\n    'val_accuracy': history_object.history['val_accuracy']\n}\nhistory_df = pd.DataFrame(history_dict)\nexcel_file_path = '/kaggle/working/training_history.xlsx'  # Replace with your desired file path\nhistory_df.to_excel(excel_file_path, index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install python-levenshtein","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:19:15.437359Z","iopub.status.idle":"2023-09-30T07:19:15.437815Z","shell.execute_reply.started":"2023-09-30T07:19:15.437623Z","shell.execute_reply":"2023-09-30T07:19:15.437644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the saved best model weights\nact_model.load_weights(filepath)\n\n# predict outputs on validation images\nprediction = act_model.predict(valid_images)\n \n# use CTC decoder\ndecoded = K.ctc_decode(prediction, \n                       input_length=np.ones(prediction.shape[0]) * prediction.shape[1],\n                       greedy=True)[0][0]\nout = K.get_value(decoded)\n\nimport Levenshtein as lv\n\ntotal_jaro = 0\ntotal_rati = 0\n# see the results\nfor i, x in enumerate(out):\n    letters=''\n    for p in x:\n        if int(p) != -1:\n            letters+=char_list[int(p)]\n    total_jaro+=lv.jaro(letters, valid_original_text[i])\n    total_rati+=lv.ratio(letters, valid_original_text[i])\n\nprint('jaro :', total_jaro/len(out))\nprint('ratio:', total_rati/len(out))","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:19:15.439123Z","iopub.status.idle":"2023-09-30T07:19:15.440654Z","shell.execute_reply.started":"2023-09-30T07:19:15.440402Z","shell.execute_reply":"2023-09-30T07:19:15.440426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict outputs on validation images\nprediction =act_model.predict(train_images[542:645])\n \n# use CTC decoder\ndecoded = K.ctc_decode(prediction,   \n                       input_length=np.ones(prediction.shape[0]) * prediction.shape[1],\n                       greedy=True)[0][0]\n\nout = K.get_value(decoded)\n\n# see the results\nfor i, x in enumerate(out):\n    print(\"original_text =  \", train_original_text[542+i])\n    print(\"predicted text = \", end = '')\n    for p in x:\n        if int(p) != -1:\n            print(char_list[int(p)], end = '')\n    plt.imshow(train_images[542+i].reshape(32,128), cmap=plt.cm.gray)\n    plt.show()\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:19:15.442408Z","iopub.status.idle":"2023-09-30T07:19:15.442793Z","shell.execute_reply.started":"2023-09-30T07:19:15.442625Z","shell.execute_reply":"2023-09-30T07:19:15.442642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract data from the history object\nacc = history_object.history[\"accuracy\"]\nval_acc = history_object.history[\"val_accuracy\"]\nloss = history_object.history[\"loss\"]\nval_loss = history_object.history[\"val_loss\"]\nepochs = range(1, len(loss) + 1)\n\n# Plot training and validation accuracy\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epochs, acc, \"b\", label=\"Training Accuracy\")\nplt.plot(epochs, val_acc, \"r\", label=\"Validation Accuracy\")\nplt.title(\"Training and Validation Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\n# Plot training and validation loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs, loss, \"b\", label=\"Training Loss\")\nplt.plot(epochs, val_loss, \"r\", label=\"Validation Loss\")\nplt.title(\"Training and Validation Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\n# Save the plot in /kaggle/output/\nplot_filename = '/kaggle/working/Accuracy_Loss_Plot.png'  # Specify the desired file name and extension\nplt.savefig(plot_filename)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:19:15.444235Z","iopub.status.idle":"2023-09-30T07:19:15.444609Z","shell.execute_reply.started":"2023-09-30T07:19:15.444428Z","shell.execute_reply":"2023-09-30T07:19:15.444444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"minimum_val_loss = np.min(history.history['val_loss'])\nbest_model_index = np.where(history.history['val_loss'] == minimum_val_loss)[0][0]\n\nbest_loss = str(history.history['loss'][best_model_index])\nbest_acc = str(history.history['accuracy'][best_model_index])\nbest_val_loss = str(history.history['val_loss'][best_model_index])\nbest_val_acc = str(history.history['val_accuracy'][best_model_index])","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:19:15.445801Z","iopub.status.idle":"2023-09-30T07:19:15.446464Z","shell.execute_reply.started":"2023-09-30T07:19:15.446280Z","shell.execute_reply":"2023-09-30T07:19:15.446298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('gdrive/My Drive/TcsInternship/HTR_Using_CRNN/Model/history.txt', 'a') as f:\n    new_data = '{},{},{},{},{},{},{},{},{},{}\\n'.format(filepath, \n                                                      optimizer_name, \n                                                      str(RECORDS_COUNT), \n                                                      e, \n                                                      str(train_images.shape[0]),\n                                                      str(valid_images.shape[0]), \n                                                      best_loss, \n                                                      best_acc, \n                                                      best_val_loss, \n                                                      best_val_acc)\n    f.write(new_data)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:19:15.448191Z","iopub.status.idle":"2023-09-30T07:19:15.448602Z","shell.execute_reply.started":"2023-09-30T07:19:15.448392Z","shell.execute_reply":"2023-09-30T07:19:15.448409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/Text_recognizer_Using_CRNN.h5')","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:19:15.450031Z","iopub.status.idle":"2023-09-30T07:19:15.450403Z","shell.execute_reply.started":"2023-09-30T07:19:15.450233Z","shell.execute_reply":"2023-09-30T07:19:15.450250Z"},"trusted":true},"execution_count":null,"outputs":[]}]}